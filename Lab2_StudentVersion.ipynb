{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIE424 (2022 Winter) Lab 2\n",
    "\n",
    "In this lab, you will be implementing the perceptron algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset\n",
    "\n",
    "Here we generate 2 dimensional arbitray dataset. $X$ is generated by using `np.random.random` (return random floats in the half-open interval [0.0, 1.0]. Then $Y$ is computed with the assumed true boundary $Xw=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: generating the data\n",
    "# n_sample: number of samples to be generated\n",
    "# w: true decision boundary\n",
    "def generate_ls_data_2class(n_sample, w):\n",
    "    X = np.random.random((n_sample, 2))\n",
    "    Y = np.sign(np.matmul(X,w))\n",
    "    check = np.sum(Y == 1)*np.sum(Y==-1)\n",
    "    if check == 0:\n",
    "        print(\"w given not valid, exist only 1 class\")\n",
    "        return None\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all components in $X$ are between [0,1], to have both classes with the boundary $Xw=0$, we need to have different signs in two componnets of vector $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true value of w used in generating the dataset\n",
    "w_true = [0.424,-0.2021]\n",
    "\n",
    "# generating the dataset\n",
    "np.random.seed(2021)\n",
    "X, Y = generate_ls_data_2class(100, w_true)\n",
    "\n",
    "# Create colormap and plot\n",
    "colors = cm.get_cmap('cool', 2)\n",
    "plt.scatter(X[:,0],X[:,1], c= colors(Y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct and Train Preceptron Model\n",
    "\n",
    "Recall the preceptron model:\n",
    "\n",
    "We have a set of points $S = \\{X_1, X_2, \\cdots, X_n\\},X_i\\in\\mathbb{R}^d$. The points are coming as a stream, and each $X_i$ is associated with a label $Y_i$ (1 or −1).\n",
    "\n",
    "We assume the points are separable, i.e. there exists a linear classifier that can correctly classify all points. We are looking to find this classifier. \n",
    "\n",
    "To generalize this and to include an intercept term, we also assume there is a given dimension $(d+1)$ for which $X_{i,d+1} = 1$ for all $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Algorithm\n",
    "\n",
    "- Initialization: $w_0$ = 0\n",
    "- for each point X\n",
    "    - if $X w_j>0$ predict $y_j =1$ else predict $y_j =−1$ \n",
    "    - if we make a mistake\n",
    "        - if true label is +1 update $w_{j+1} = w_j + X$\n",
    "        - if true label is −1 update $w_{j+1} = w_j - X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, iterations):\n",
    "        self.w = np.zeros((2,1))\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def train(self, X, Y, lr=1, plot=False):\n",
    "        for i in range(self.iterations):\n",
    "            # Insert your code here\n",
    "            # Update w using the preceptron algorithm:\n",
    "            # Hint: you can use self.w to access the value of w            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if plot:\n",
    "                plt.figure(i)\n",
    "                plt.scatter(X[:,0],X[:,1], c= colors(Y))\n",
    "                slope = -1 * self.w[0] / self.w[1]\n",
    "                plt.plot([0, 1/slope],[0, 1])\n",
    "                plt.show()\n",
    "            if self.err(X, Y) == 0:\n",
    "                break\n",
    "                self.conv_iter = i+1\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Insert your code here\n",
    "        # return the prediction of X (n by 2 array) made by the fitted model\n",
    "        # Hint: you can use self.w to access the value of w\n",
    "        return \n",
    "    \n",
    "    def err(self, X, Y):\n",
    "        # Insert your code here\n",
    "        # return percentage of samples where the prediction made by the fitted model are not correct\n",
    "        # Hint: you can use self.w to access the value of w\n",
    "        return \n",
    "\n",
    "p = Perceptron(100)\n",
    "p.train(X, Y)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c= colors(Y))\n",
    "\n",
    "colors_2 = cm.get_cmap('binary', 20)\n",
    "\n",
    "slope = -1 * p.w[0, 0] / p.w[1, 0]\n",
    "plt.plot([0, 1/slope],[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the training error\n",
    "p.err(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "How does changing the learning rate affect how long it takes for the perceptron algorithm to converge?\n",
    "\n",
    "How does changing the order at which the perceptron algorithm sees the data points affect the convergence time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Preceptron Model with Intercept\n",
    "\n",
    "Now we consider the boundary between two classes to be $Xw+b=0$ where $b$ is the bias term.\n",
    "\n",
    "We use the idea discussed in the lecture to expand $X$ to add a given dimension $(d+1)$ for which $X_{i,d+1} = 1$ for all $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset (Expanding X and update Y)\n",
    "\n",
    "# true value of w and b used in generating the dataset\n",
    "b_true = -0.15\n",
    "w_true_expand = np.zeros(len(w_true)+1)\n",
    "w_true_expand[0:len(w_true)] = w_true\n",
    "w_true_expand[-1] = b_true\n",
    "\n",
    "# expand X\n",
    "X_expand = np.ones((X.shape[0],X.shape[1]+1))\n",
    "X_expand[:,0:2]=X\n",
    "\n",
    "# update Y\n",
    "Y_update = np.sign(np.matmul(X_expand,w_true_expand))\n",
    "\n",
    "colors = cm.get_cmap('cool', 2)\n",
    "plt.scatter(X[:,0],X[:,1], c= colors(Y_update))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronIntercept(Perceptron):\n",
    "    \n",
    "    def __init__(self, iterations):\n",
    "        self.w = np.zeros((3,1))\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def train(self, X, Y, lr=1, plot=False):\n",
    "        for i in range(self.iterations):\n",
    "            # Insert your code here\n",
    "            # Update w using the preceptron algorithm:\n",
    "            # Hint: you can use self.w to access the value of w            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if plot:\n",
    "                plt.figure(i)\n",
    "                plt.scatter(X[:,0],X[:,1], c= colors(Y))\n",
    "                plt.plot([-w[2, 0]/w[0, 0], 1],[0, -(w[0, 0]+w[2, 0])/ w[1, 0]])\n",
    "                plt.show()\n",
    "            if self.err(X, Y) == 0:\n",
    "                break\n",
    "                self.conv_iter = i+1\n",
    "    \n",
    "\n",
    "p = PerceptronIntercept(1500)\n",
    "p.train(X_expand, Y_update)\n",
    "\n",
    "plt.scatter(X_expand[:,0],X_expand[:,1], c= colors(Y_update))\n",
    "\n",
    "colors_2 = cm.get_cmap('binary', 20)\n",
    "\n",
    "w = p.w/np.linalg.norm(p.w)\n",
    "\n",
    "plt.plot([-w[2, 0]/w[0, 0], 1],[0, -(w[0, 0]+w[2, 0])/ w[1, 0]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the training error\n",
    "p.err(X_expand, Y_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
